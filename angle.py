import matplotlib.pyplot as plt
import numpy as np
from pathlib import Path
import pandas as pd
from joblib import dump, load
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import train_test_split, cross_val_score, learning_curve
from sklearn.linear_model import LinearRegression, RANSACRegressor, QuantileRegressor
from sklearn.metrics import mean_absolute_error, make_scorer
from sys import path
import optuna
from xgboost import XGBRegressor
from EDA_angles import get_selected_params
from time import perf_counter


def bayes_opt(X_train, y_train):
    def multioutput_mae(y_true, y_pred):
        return np.mean(np.abs(y_true - y_pred))

    mae_scorer = make_scorer(multioutput_mae, greater_is_better=False)
    def objective(trial):
        params = {
            "n_estimators": trial.suggest_int("n_estimators", 40, 300),
            "eval_metric": "mae",
            "max_depth": trial.suggest_int("max_depth", 3, 10),
            "learning_rate": trial.suggest_float("learning_rate", 0.01, 0.3, log=True),
            "subsample": trial.suggest_float("subsample", 0.6, 1.0),
            "colsample_bytree": trial.suggest_float("colsample_bytree", 0.6, 1.0),
            "random_state": 42,
            "n_jobs": -1,
            "verbosity": 0,
        }
        
        model = XGBRegressor(**params)
        scores = -cross_val_score(model, X_train, y_train, cv=3, scoring=mae_scorer, n_jobs=-1)
        return scores.mean()

    print("\n–ó–∞–ø—É—Å–∫ Optuna...")
    study = optuna.create_study(direction="minimize")
    study.optimize(objective, n_trials=30)

    print("–õ—É—á—à–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã (Optuna):")
    print(study.best_params)
    print(f"–õ—É—á—à–∏–π MAE: {study.best_value:.3f} px")


def angular_error_deg(y_true, y_pred):
    """
    –í—ã—á–∏—Å–ª—è–µ—Ç –æ—à–∏–±–∫—É –º–µ–∂–¥—É –∏—Å—Ç–∏–Ω–Ω—ã–º–∏ –∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–º–∏ —É–≥–ª–∞–º–∏ (–≤ –≥—Ä–∞–¥—É—Å–∞—Ö)
    —Å —É—á—ë—Ç–æ–º —Ü–∏–∫–ª–∏—á–Ω–æ—Å—Ç–∏. –î–ª—è –º–∞–ª—ã—Ö —É–≥–ª–æ–≤ (-3..3) –ø–æ—á—Ç–∏ —Å–æ–≤–ø–∞–¥–∞–µ—Ç —Å –ø—Ä–æ—Å—Ç–æ–π —Ä–∞–∑–Ω–æ—Å—Ç—å—é.
    """
    y_true = np.asarray(y_true)
    y_pred = np.asarray(y_pred)
    diff = y_pred - y_true
    # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –∫ [-180, 180)
    errors = (diff + 180) % 360 - 180
    return errors


def evaluate_angle_predictions(y_true, y_pred, title="–û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è —É–≥–ª–∞"):
    """
    –ü–æ–ª–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è —É–≥–ª–∞ —Å –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–µ–π.
    
    –ü–∞—Ä–∞–º–µ—Ç—Ä—ã:
        y_true : array-like ‚Äî –∏—Å—Ç–∏–Ω–Ω—ã–µ —É–≥–ª—ã (–≥—Ä–∞–¥—É—Å—ã)
        y_pred : array-like ‚Äî –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–µ —É–≥–ª—ã (–≥—Ä–∞–¥—É—Å—ã)
        title : str ‚Äî –∑–∞–≥–æ–ª–æ–≤–æ–∫ –≥—Ä–∞—Ñ–∏–∫–æ–≤
    """
    y_true = np.asarray(y_true)
    y_pred = np.asarray(y_pred)
    
    # 1. –û—à–∏–±–∫–∏
    errors = angular_error_deg(y_true, y_pred)
    mae = np.mean(np.abs(errors))
    rmse = np.sqrt(np.mean(errors ** 2))
    std_error = np.std(errors)
    
    # 2. –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    print(f"üîç –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –æ—à–∏–±–æ–∫ (–≤ –≥—Ä–∞–¥—É—Å–∞—Ö):")
    print(f"  MAE (—Å—Ä–µ–¥–Ω—è—è –∞–±—Å–æ–ª—é—Ç–Ω–∞—è –æ—à–∏–±–∫–∞): {mae:.4f}¬∞")
    print(f"  RMSE (—Å—Ä–µ–¥–Ω–µ–∫–≤–∞–¥—Ä–∞—Ç–∏—á–Ω–∞—è –æ—à–∏–±–∫–∞): {rmse:.4f}¬∞")
    print(f"  –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ –æ—à–∏–±–∫–∏:  {std_error:.4f}¬∞")
    print(f"  –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –æ—à–∏–±–∫–∞:           {np.max(np.abs(errors)):.4f}¬∞")
    print(f"  95-–π –ø–µ—Ä—Ü–µ–Ω—Ç–∏–ª—å –æ—à–∏–±–∫–∏:        {np.percentile(np.abs(errors), 95):.4f}¬∞")
    
    # 3. –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è
    fig, axs = plt.subplots(1, 3, figsize=(15, 4))
    
    # a) Scatter plot: –∏—Å—Ç–∏–Ω–Ω—ã–π vs –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–π
    axs[0].scatter(y_true, y_pred, alpha=0.6, s=20)
    axs[0].plot([-3, 3], [-3, 3], 'r--', label='–ò–¥–µ–∞–ª—å–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ')
    axs[0].set_xlabel('–ò—Å—Ç–∏–Ω–Ω—ã–π —É–≥–æ–ª (¬∞)')
    axs[0].set_ylabel('–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–π —É–≥–æ–ª (¬∞)')
    axs[0].set_title('–ò—Å—Ç–∏–Ω–Ω—ã–π vs –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–π')
    axs[0].legend()
    axs[0].grid(True)
    
    # b) –ì–∏—Å—Ç–æ–≥—Ä–∞–º–º–∞ –æ—à–∏–±–æ–∫
    axs[1].hist(errors, bins=30, edgecolor='black', alpha=0.7)
    axs[1].axvline(0, color='red', linestyle='--')
    axs[1].set_xlabel('–û—à–∏–±–∫–∞ (¬∞)')
    axs[1].set_ylabel('–ß–∞—Å—Ç–æ—Ç–∞')
    axs[1].set_title(f'–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –æ—à–∏–±–æ–∫\n(MAE = {mae:.4f}¬∞)')
    axs[1].grid(True)
    
    # c) –û—à–∏–±–∫–∏ –ø–æ –≤–µ–ª–∏—á–∏–Ω–µ –∏—Å—Ç–∏–Ω–Ω–æ–≥–æ —É–≥–ª–∞
    axs[2].scatter(y_true, errors, alpha=0.6, s=20)
    axs[2].axhline(0, color='red', linestyle='--')
    axs[2].set_xlabel('–ò—Å—Ç–∏–Ω–Ω—ã–π —É–≥–æ–ª (¬∞)')
    axs[2].set_ylabel('–û—à–∏–±–∫–∞ (¬∞)')
    axs[2].set_title('–û—à–∏–±–∫–∞ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –∏—Å—Ç–∏–Ω–Ω–æ–≥–æ —É–≥–ª–∞')
    axs[2].grid(True)
    
    plt.suptitle(title, fontsize=14)
    plt.tight_layout(rect=[0, 0.03, 1, 0.95])
    plt.show()
    
    return {
        'mae': mae,
        'rmse': rmse,
        'std_error': std_error,
        'max_error': np.max(np.abs(errors)),
        'percentile_95': np.percentile(np.abs(errors), 95),
        'errors': errors
    }


path_dir = Path(path[0])

all_data = pd.read_csv((path_dir / "angles\\combined_data_angle.csv"))

delta = 1

X, y = get_selected_params(method=None, num_of_params=8, show_img=False, save_img=False)
print(len(X))

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=1)
test_index = list(y_test.index)


# # –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –º–æ–¥–µ–ª–µ–π
# bayes_opt(X, y)


model = LinearRegression()
# model = QuantileRegressor(quantile=0.5, alpha=0.0, solver='highs')
# model = XGBRegressor(n_estimators=249, max_depth=10, learning_rate=0.037, eval_metric=mean_absolute_error,
#                       random_state=1, subsample=0.64, colsample_bytree=0.7)


print("–ó–Ω–∞—á–µ–Ω–∏–µ –∫—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏–∏ –º–æ–¥–µ–ª–∏ (MAE):", np.mean(cross_val_score(model, X, y, cv=5,
                                                                  scoring='neg_mean_absolute_error') * -1), "\n")
print("–ó–Ω–∞—á–µ–Ω–∏–µ –∫—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏–∏ –º–æ–¥–µ–ª–∏ (MSE):", np.mean(cross_val_score(model, X, y, cv=5,
                                                                  scoring='neg_mean_squared_error') * -1), "\n")

model.fit(X_train, y_train)

start = perf_counter()
y_pred = model.predict(X_test)
finish = perf_counter()
print("–í—Ä–µ–º—è –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞ –º–æ–¥–µ–ª–∏:", round((finish - start) / X_test.shape[0] * 1000000, 5), "–º–∫—Ä —Å–µ–∫.\n")

# # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ (–æ–±—É—á–µ–Ω–∏–µ –Ω–∞ –ø–æ–ª–Ω–æ–º –Ω–∞–±–æ—Ä–µ –¥–∞–Ω–Ω—ã—Ö)
# model.fit(np.array(X), y)
# dump(model, 'angles_calc.joblib')


evaluate_angle_predictions(y_test, y_pred)

